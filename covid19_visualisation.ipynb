{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Completed\n",
    "# Google API integration - extract data from spreadsheet\n",
    "# Map configuration & icons\n",
    "# Push to website (hosted on BlueHost) automatically\n",
    "# Secure storage of file without exposure to blog\n",
    "# Run the script Online in a cron format\n",
    "\n",
    "#TODO:\n",
    "# Integrating code with matching algorithm & writing matched entry into spreadsheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Basic\n",
    "from __future__ import print_function\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from shapely.geometry import Point\n",
    "\n",
    "#Google Docs integration\n",
    "import pickle\n",
    "import os.path\n",
    "from googleapiclient.discovery import build\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "\n",
    "#Map\n",
    "import keplergl\n",
    "\n",
    "#DB Connections\n",
    "import mysql.connector as sql_con\n",
    "from sqlalchemy import create_engine\n",
    "import cred_config as cc\n",
    "\n",
    "#File Transfer\n",
    "import ftplib\n",
    "import os\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "default_r=0.5\n",
    "\n",
    "#Approximation\n",
    "lat_deg_to_km = 95.0\n",
    "lon_deg_to_km = 110.0\n",
    "buffer_radius = 1/np.sqrt(95*95+110*110)\n",
    "\n",
    "\n",
    "# If modifying these scopes, delete the file token.pickle.\n",
    "SCOPES = ['https://www.googleapis.com/auth/spreadsheets']\n",
    "\n",
    "# The ID and range of a sample spreadsheet.\n",
    "volunteer_sheet_data = [{'source':'GreenDream','sheet_id':'1e9H5yO1COGLNfA3lyZxRSgc2llDKRSFZX92Ov8VOzOs','range':'Form Responses 1!A1:K1000'}]\n",
    "senior_citizen_sheet_data = [{'source':'GreenDream','sheet_id':'1KrZCG_fYvImIy_-549VB0rzbbfKHkkbmJG0l6DH01zM','range':'Form Responses 1!A1:K1000'}]\n",
    "\n",
    "public_file_name= 'output/COVID_SOS_v0.html'\n",
    "private_file_name= 'output/private_COVID_SOS_v0.html'\n",
    "\n",
    "#FORMAT: from map_config.filename import *\n",
    "from map_config.map_config_private import *\n",
    "from map_config.map_config_public import *\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def map_config_fn(map_config_file):\n",
    "    with open(map_config_file,'r') as config_file_reader:\n",
    "        config_file = config_file_reader.read()\n",
    "        exec(config_file, None, locals())\n",
    "    dx = live_config.copy()\n",
    "    return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connections(con_name):\n",
    "    if(con_name=='db_read'):\n",
    "        cred_r=cc.credentials['covid_sos_read']\n",
    "        server_con = sql_con.connect(user=cred_r['user'], password=cred_r['password'], host=cred_r['host'],database=cred_r['database'])\n",
    "    if(con_name=='db_write'):\n",
    "        cred_w = cc.credentials['covid_sos_write']\n",
    "        server_con = create_engine(\"mysql+pymysql://{user}:{password}@{host}/{database}\".format(user = cred_w['user'], password = cred_w['password'], host = cred_w['host'], database = cred_w['database']), pool_size=10, max_overflow=20, echo=False)\n",
    "    if(con_name=='ftp'):\n",
    "        FTP_con = cc.credentials['ftp']\n",
    "        server_con = ftplib.FTP(host=FTP_con['host'], user=FTP_con['user'], passwd=FTP_con['password'])\n",
    "    return server_con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def google_api_activation():\n",
    "    creds = None\n",
    "    # The file token.pickle stores the user's access and refresh tokens, and is\n",
    "    # created automatically when the authorization flow completes for the first\n",
    "    # time.\n",
    "    if os.path.exists('support_files/token.pickle'):\n",
    "        with open('support_files/token.pickle', 'rb') as token1:\n",
    "            creds = pickle.load(token1)\n",
    "    # If there are no (valid) credentials available, let the user log in.\n",
    "    if not creds or not creds.valid:\n",
    "        if creds and creds.expired and creds.refresh_token:\n",
    "            creds.refresh(Request())\n",
    "        else:\n",
    "            flow = InstalledAppFlow.from_client_secrets_file('support_files/credentials.json', SCOPES)\n",
    "            creds = flow.run_local_server(port=0)\n",
    "        # Save the credentials for the next run\n",
    "        with open('support_files/token.pickle', 'wb') as token:\n",
    "            pickle.dump(creds, token)\n",
    "    service = build('sheets', 'v4', credentials=creds)\n",
    "    return service\n",
    "\n",
    "def extract_all_sheets(service,sheets_dict):\n",
    "    sheets_df=pd.DataFrame()\n",
    "    for i in sheets_dict:\n",
    "        source = i['source']\n",
    "        sheet_id=i['sheet_id']\n",
    "        range_name=i['range']\n",
    "        sheets_df_x = sheet_header(extract_sheet(service,sheet_id,range_name),source)\n",
    "        sheets_df = sheets_df.append(sheets_df_x)\n",
    "    return sheets_df\n",
    "\n",
    "def extract_sheet(service,sheet_id,range_name):\n",
    "    # Call the Sheets API\n",
    "    sheet = service.spreadsheets()\n",
    "    result = sheet.values().get(spreadsheetId=sheet_id,range=range_name).execute()\n",
    "    return result\n",
    "\n",
    "def sheet_header(df,source):\n",
    "    input_data = pd.DataFrame(df['values'])\n",
    "    new_header = input_data.iloc[0] #grab the first row for the header\n",
    "    input_data = input_data[1:] #take the data less the header row\n",
    "    input_data.columns = new_header #\n",
    "    input_data['source']=source\n",
    "    return input_data\n",
    "\n",
    "\n",
    "def sheet_clean_up(df,default_r,buffer_radius):\n",
    "    \n",
    "    # Sample Data\n",
    "    df = gpd.GeoDataFrame(df)\n",
    "    df['Lat']=df['GeoCodeLat'].astype(float).fillna(0)\n",
    "    df['Lon']=df['GeoCodeLon'].astype(float).fillna(0)\n",
    "    df['radius']=default_r\n",
    "    geometry = df.apply(lambda x: Point(x['Lon'],x['Lat']).buffer(buffer_radius*x.radius),axis=1)\n",
    "    crs = {'init': 'epsg:4326'}\n",
    "    f_df = gpd.GeoDataFrame(df, crs=crs, geometry=geometry).drop(columns=['GeoCodeLat','GeoCodeLon'])\n",
    "    return f_df\n",
    "\n",
    "\n",
    "def html_file_changes(output_file_name):\n",
    "    with open(output_file_name,'r') as output_file_reader:\n",
    "        bs = output_file_reader.read()\n",
    "    soup = BeautifulSoup(bs, 'html.parser')\n",
    "    soup.title.string='COVID SOS Initiative - Connecting Volunteers with Requests'\n",
    "    with open(output_file_name, \"w\") as file:\n",
    "        file.write(str(soup))\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def public_map(v_df,r_df,output_file_name):\n",
    "    v_df['WhatsApp Contact Number']=9582148040\n",
    "    r_df['Mobile Number']=9582148040\n",
    "    map_1 = keplergl.KeplerGl(height=800,data={'volunteer_data':v_df[v_df['Lat']!=0],'requests_data':r_df[r_df['Lat']!=0]})\n",
    "    print('The public map contains ', v_df[v_df['Lat']!=0].shape[0],' volunteers and ', r_df[r_df['Lat']!=0].shape[0], ' pending requests')\n",
    "    #variable live_config is defined when \"file\" is executed\n",
    "    map_1.config = public_live_config\n",
    "    map_1.save_to_html(file_name=output_file_name)\n",
    "    html_file_changes(output_file_name)\n",
    "    push_file_to_server(output_file_name,output_file_name)\n",
    "    push_file_to_server(output_file_name,'output/share_and_survive_v0_dark.html')\n",
    "    return map_1\n",
    "\n",
    "def private_map(v_df,r_df,output_file_name):\n",
    "    r_df = r_df[r_df['Task Status']=='Pending']\n",
    "    map_1 = keplergl.KeplerGl(height=800,data={'volunteer_data':v_df[v_df['Lat']!=0],'requests_data':r_df[r_df['Lat']!=0]})\n",
    "    print('The private Map contains ', v_df[v_df['Lat']!=0].shape[0],' volunteers and ', r_df[r_df['Lat']!=0].shape[0], ' pending requests')\n",
    "    #variable live_config is defined when \"file\" is executed\n",
    "    map_1.config = private_live_config\n",
    "    map_1.save_to_html(file_name=output_file_name)\n",
    "    html_file_changes(output_file_name)\n",
    "    push_file_to_server(output_file_name,output_file_name)\n",
    "    return map_1\n",
    "\n",
    "\n",
    "def push_file_to_server(File2Send,Url2Store):\n",
    "    ftp = connections('ftp')\n",
    "    Output_Directory = \"/public_html/covid19/\"\n",
    "    ftp.cwd(Output_Directory)\n",
    "    with open(File2Send, \"rb\") as server_f:\n",
    "        ftp.storbinary('STOR ' + os.path.basename(Url2Store), server_f) \n",
    "    print('File saved to server at URL: www.thebangaloreguy.com/covid19/'+(Url2Store).split('/')[-1])\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    #Fetching Data from sheets\n",
    "    service = google_api_activation()\n",
    "\n",
    "    volunteer_df = extract_all_sheets(service,volunteer_sheet_data)\n",
    "    requests_df = extract_all_sheets(service,senior_citizen_sheet_data)\n",
    "    \n",
    "    v_df = sheet_clean_up(volunteer_df,default_r,buffer_radius)\n",
    "    v_df['icon']='location'\n",
    "    \n",
    "    r_df = sheet_clean_up(requests_df,default_r,buffer_radius)\n",
    "    r_df['icon']='home'\n",
    "    \n",
    "    private_map_v1 = private_map(v_df,r_df,private_file_name)\n",
    "    public_map_v1 = public_map(v_df,r_df,public_file_name)\n",
    "    #Processing Data\n",
    "    return v_df, r_df, private_map_v1,public_map_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Guide: https://github.com/keplergl/kepler.gl/blob/master/docs/keplergl-jupyter/user-guide.md\n",
      "The private Map contains  94  volunteers and  25  pending requests\n",
      "Map saved to output/private_COVID_SOS_v0.html!\n",
      "File saved to server at URL: www.thebangaloreguy.com/covid19/private_COVID_SOS_v0.html\n",
      "User Guide: https://github.com/keplergl/kepler.gl/blob/master/docs/keplergl-jupyter/user-guide.md\n",
      "The public map contains  94  volunteers and  27  pending requests\n",
      "Map saved to output/COVID_SOS_v0.html!\n",
      "File saved to server at URL: www.thebangaloreguy.com/covid19/COVID_SOS_v0.html\n",
      "File saved to server at URL: www.thebangaloreguy.com/covid19/share_and_survive_v0_dark.html\n"
     ]
    }
   ],
   "source": [
    "v_df, r_df, p1,p2=main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('map_config/map_config_public.py','w') as f:\n",
    "#     f.write('public_live_config = {}'.format(map_1.config))\n",
    "# with open('map_config/map_config_new.py','r') as f:\n",
    "#     print(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#v_query = (\"\"\"Select * from volunteers\"\"\")\n",
    "#v_data = pd.read_sql(v_query,server_con)\n",
    "\n",
    "#v_df.to_sql(name = 'volunteers', con = engine, schema='thebang7_COVID_SOS', if_exists='append', index = False,index_label=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Delete command\n",
    "#ftp.delete(os.path.basename(File2Send))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# from folium import Map, Marker, GeoJson\n",
    "# from folium.plugins import MarkerCluster\n",
    "\n",
    "\n",
    "# v_df\n",
    "\n",
    "# #quick visualization on map of raw data\n",
    "\n",
    "# m = Map(location= [12.97194, 77.59369], zoom_start= 12, tiles=\"cartodbpositron\", \n",
    "#         attr= '© <a href=\"http://www.openstreetmap.org/copyright\">OpenStreetMap</a> contributors © <a href=\"http://cartodb.com/attributions#basemaps\">CartoDB</a>' \n",
    "# )\n",
    "# mc = MarkerCluster()\n",
    "\n",
    "# for i in v_df.index:\n",
    "#     mk = Marker(location=[v_df.loc[i,'Lat'],v_df.loc[i,'Lon']])\n",
    "#     mk.add_to(mc)\n",
    "# mc.add_to(m)\n",
    "\n",
    "# m.save('folium_view.html')\n",
    "# m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
